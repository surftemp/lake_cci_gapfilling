{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract DINEOF and DINCAE Metrics from Pipeline Outputs\n",
    "\n",
    "This notebook extracts the following metrics:\n",
    "- **dineof_cvrms**: Expected error calculated by cross-validation (from DINEOF logs)\n",
    "- **dincae_cvrms**: CV_RMS from DINCAE cv_rms.txt files\n",
    "- **variance_initial**: Total variance of the initial matrix (from DINEOF logs)\n",
    "- **variance_reconstructed**: Total variance of the reconstructed matrix (from DINEOF logs)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your directories here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINEOF dir (logs): /gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/anomaly-20260131-219f0d-exp0_baseline_both\n",
      "DINCAE dir: /gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/anomaly-20260131-219f0d-exp0_baseline_both\n",
      "Output dir: /gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/anomaly-20260131-219f0d-exp0_baseline_both\n",
      "Alpha slug: a1000\n",
      "Lake locations CSV: filtered_lakes_lake_summary_results_from2000_QL45.csv\n",
      "\n",
      "Logs dir exists: False\n",
      "DINCAE dir exists: False\n",
      "Lake locations CSV exists: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CONFIGURE THESE PATHS\n",
    "# ============================================\n",
    "\n",
    "folder_name = \"/gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/anomaly-20260131-219f0d-exp0_baseline_both/\"\n",
    "\n",
    "# Directory containing logs/ folder (DINEOF outputs)\n",
    "DINEOF_DIR = f\"/gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/{folder_name}/\"\n",
    "\n",
    "# Directory containing dincae/ folder (DINCAE outputs)\n",
    "# Set to same as DINEOF_DIR if they're in the same run root\n",
    "DINCAE_DIR = f\"/gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/{folder_name}/\"\n",
    "\n",
    "# Output directory (None = same as DINEOF_DIR)\n",
    "OUTPUT_DIR = None\n",
    "\n",
    "# Alpha slug for DINCAE subdirectories\n",
    "ALPHA_SLUG = \"a1000\"\n",
    "\n",
    "# Lake locations CSV file (should be in the same folder as this notebook)\n",
    "LAKE_LOCATIONS_CSV = \"filtered_lakes_lake_summary_results_from2000_QL45.csv\"\n",
    "\n",
    "# ============================================\n",
    "\n",
    "dineof_base = Path(DINEOF_DIR)\n",
    "dincae_base = Path(DINCAE_DIR)\n",
    "logs_dir = dineof_base / \"logs\"\n",
    "out_path = Path(OUTPUT_DIR) if OUTPUT_DIR else dineof_base\n",
    "\n",
    "print(f\"DINEOF dir (logs): {dineof_base}\")\n",
    "print(f\"DINCAE dir: {dincae_base}\")\n",
    "print(f\"Output dir: {out_path}\")\n",
    "print(f\"Alpha slug: {ALPHA_SLUG}\")\n",
    "print(f\"Lake locations CSV: {LAKE_LOCATIONS_CSV}\")\n",
    "print()\n",
    "print(f\"Logs dir exists: {logs_dir.exists()}\")\n",
    "print(f\"DINCAE dir exists: {(dincae_base / 'dincae').exists()}\")\n",
    "print(f\"Lake locations CSV exists: {Path(LAKE_LOCATIONS_CSV).exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lake_id_from_filename(filename: str) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Extract lake ID from log filename.\n",
    "    \n",
    "    Expected patterns:\n",
    "      - chain_lake3007_row0_12345.out\n",
    "      - dineof_lake3007_row0_12345.out\n",
    "    \"\"\"\n",
    "    match = re.search(r'lake(\\d+)', filename, re.IGNORECASE)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_dineof_metrics_from_content(content: str) -> Dict[str, Optional[float]]:\n",
    "    \"\"\"\n",
    "    Extract DINEOF metrics from log file content.\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'dineof_cvrms': None,\n",
    "        'variance_initial': None,\n",
    "        'variance_reconstructed': None,\n",
    "    }\n",
    "    \n",
    "    # Pattern for: expected error calculated by cross-validation          0.7828\n",
    "    cvrms_pattern = r'expected\\s+error\\s+calculated\\s+by\\s+cross-validation\\s+([\\d.]+(?:[eE][+-]?\\d+)?)'\n",
    "    match = re.search(cvrms_pattern, content, re.IGNORECASE)\n",
    "    if match:\n",
    "        try:\n",
    "            metrics['dineof_cvrms'] = float(match.group(1))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    # Pattern for: total variance of the initial matrix    4.9608612560127048\n",
    "    var_init_pattern = r'total\\s+variance\\s+of\\s+the\\s+initial\\s+matrix\\s+([\\d.]+(?:[eE][+-]?\\d+)?)'\n",
    "    match = re.search(var_init_pattern, content, re.IGNORECASE)\n",
    "    if match:\n",
    "        try:\n",
    "            metrics['variance_initial'] = float(match.group(1))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    # Pattern for: total variance of the reconstructed matrix    5.4089640144865028\n",
    "    var_recon_pattern = r'total\\s+variance\\s+of\\s+the\\s+reconstructed\\s+matrix\\s+([\\d.]+(?:[eE][+-]?\\d+)?)'\n",
    "    match = re.search(var_recon_pattern, content, re.IGNORECASE)\n",
    "    if match:\n",
    "        try:\n",
    "            metrics['variance_reconstructed'] = float(match.group(1))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def extract_dincae_cvrms(cv_rms_path: Path) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Extract CV_RMS from a DINCAE cv_rms.txt file.\n",
    "    \n",
    "    Expected content format:\n",
    "        CV_RMS 1.098578\n",
    "    \"\"\"\n",
    "    if not cv_rms_path.exists():\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        content = cv_rms_path.read_text().strip()\n",
    "        match = re.search(r'CV_RMS\\s+([\\d.]+(?:[eE][+-]?\\d+)?)', content, re.IGNORECASE)\n",
    "        if match:\n",
    "            return float(match.group(1))\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def find_dincae_cv_files(dincae_base: Path, alpha_slug: str = \"a1000\") -> Dict[int, Path]:\n",
    "    \"\"\"\n",
    "    Find all DINCAE cv_rms.txt files and map them to lake IDs.\n",
    "    \n",
    "    Expected structure: {dincae_base}/dincae/{lake_id9}/{alpha_slug}/cv_rms.txt\n",
    "    \"\"\"\n",
    "    dincae_dir = dincae_base / \"dincae\"\n",
    "    if not dincae_dir.exists():\n",
    "        return {}\n",
    "    \n",
    "    lake_cv_files = {}\n",
    "    \n",
    "    for lake_dir in dincae_dir.iterdir():\n",
    "        if not lake_dir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            lake_id = int(lake_dir.name)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        \n",
    "        cv_rms_path = lake_dir / alpha_slug / \"cv_rms.txt\"\n",
    "        if cv_rms_path.exists():\n",
    "            lake_cv_files[lake_id] = cv_rms_path\n",
    "    \n",
    "    return lake_cv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process DINEOF Log Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 .out files in /gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/anomaly-20260131-219f0d-exp0_baseline_both/logs\n"
     ]
    }
   ],
   "source": [
    "# Find all .out log files\n",
    "log_files = sorted(logs_dir.glob(\"*.out\")) if logs_dir.exists() else []\n",
    "print(f\"Found {len(log_files)} .out files in {logs_dir}\")\n",
    "\n",
    "if log_files:\n",
    "    print(\"\\nFirst 5 files:\")\n",
    "    for f in log_files[:5]:\n",
    "        print(f\"  {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted DINEOF metrics for 0 lakes\n",
      "Lakes without DINEOF data: 0\n"
     ]
    }
   ],
   "source": [
    "# Process all DINEOF log files\n",
    "lake_data: Dict[int, Dict] = {}\n",
    "skipped_lakes_dineof: List[int] = []\n",
    "files_without_lake_id: List[str] = []\n",
    "\n",
    "for log_path in log_files:\n",
    "    filename = log_path.name\n",
    "    lake_id = extract_lake_id_from_filename(filename)\n",
    "    \n",
    "    if lake_id is None:\n",
    "        files_without_lake_id.append(filename)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        content = log_path.read_text(errors='replace')\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not read {log_path}: {e}\")\n",
    "        if lake_id not in lake_data:\n",
    "            skipped_lakes_dineof.append(lake_id)\n",
    "        continue\n",
    "    \n",
    "    metrics = extract_dineof_metrics_from_content(content)\n",
    "    has_data = any(v is not None for v in metrics.values())\n",
    "    \n",
    "    if has_data:\n",
    "        if lake_id in lake_data:\n",
    "            # Merge: prefer non-None values\n",
    "            existing = lake_data[lake_id]\n",
    "            for key, value in metrics.items():\n",
    "                if value is not None and existing.get(key) is None:\n",
    "                    existing[key] = value\n",
    "        else:\n",
    "            lake_data[lake_id] = {'lake_id': lake_id, **metrics}\n",
    "    else:\n",
    "        if lake_id not in lake_data:\n",
    "            skipped_lakes_dineof.append(lake_id)\n",
    "\n",
    "print(f\"\\nExtracted DINEOF metrics for {len(lake_data)} lakes\")\n",
    "print(f\"Lakes without DINEOF data: {len(set(skipped_lakes_dineof))}\")\n",
    "if files_without_lake_id:\n",
    "    print(f\"Files ignored (no lake_id): {len(files_without_lake_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process DINCAE cv_rms.txt Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 cv_rms.txt files in /gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/anomaly-20260131-219f0d-exp0_baseline_both/dincae\n"
     ]
    }
   ],
   "source": [
    "# Find DINCAE cv_rms.txt files\n",
    "dincae_cv_files = find_dincae_cv_files(dincae_base, ALPHA_SLUG)\n",
    "print(f\"Found {len(dincae_cv_files)} cv_rms.txt files in {dincae_base / 'dincae'}\")\n",
    "\n",
    "if dincae_cv_files:\n",
    "    print(\"\\nFirst 5:\")\n",
    "    for lake_id, path in list(dincae_cv_files.items())[:5]:\n",
    "        print(f\"  Lake {lake_id}: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted DINCAE metrics: 0\n",
      "Lakes with DINCAE only (no DINEOF): 0\n",
      "DINCAE files skipped (parse error): 0\n"
     ]
    }
   ],
   "source": [
    "# Process DINCAE cv_rms.txt files\n",
    "skipped_lakes_dincae: List[int] = []\n",
    "dincae_only_lakes: List[int] = []\n",
    "\n",
    "for lake_id, cv_path in dincae_cv_files.items():\n",
    "    cvrms = extract_dincae_cvrms(cv_path)\n",
    "    \n",
    "    if cvrms is not None:\n",
    "        if lake_id in lake_data:\n",
    "            lake_data[lake_id]['dincae_cvrms'] = cvrms\n",
    "        else:\n",
    "            # Lake has DINCAE data but no DINEOF data\n",
    "            lake_data[lake_id] = {\n",
    "                'lake_id': lake_id,\n",
    "                'dineof_cvrms': None,\n",
    "                'dincae_cvrms': cvrms,\n",
    "                'variance_initial': None,\n",
    "                'variance_reconstructed': None,\n",
    "            }\n",
    "            dincae_only_lakes.append(lake_id)\n",
    "    else:\n",
    "        skipped_lakes_dincae.append(lake_id)\n",
    "\n",
    "# Ensure all records have dincae_cvrms key\n",
    "for lake_id, data in lake_data.items():\n",
    "    if 'dincae_cvrms' not in data:\n",
    "        data['dincae_cvrms'] = None\n",
    "\n",
    "print(f\"\\nExtracted DINCAE metrics: {sum(1 for d in lake_data.values() if d.get('dincae_cvrms') is not None)}\")\n",
    "print(f\"Lakes with DINCAE only (no DINEOF): {len(dincae_only_lakes)}\")\n",
    "print(f\"DINCAE files skipped (parse error): {len(skipped_lakes_dincae)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data extracted!\n"
     ]
    }
   ],
   "source": [
    "# Compile skipped lakes\n",
    "skipped_lakes = sorted(set(skipped_lakes_dineof) - set(lake_data.keys()))\n",
    "\n",
    "# Convert to DataFrame with proper column order\n",
    "data_list = sorted(lake_data.values(), key=lambda x: x['lake_id'])\n",
    "\n",
    "if data_list:\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df = df[['lake_id', 'dineof_cvrms', 'dincae_cvrms', 'variance_initial', 'variance_reconstructed']]\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    display(df.head(20))\n",
    "else:\n",
    "    df = pd.DataFrame(columns=['lake_id', 'dineof_cvrms', 'dincae_cvrms', 'variance_initial', 'variance_reconstructed'])\n",
    "    print(\"No data extracted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df) > 0:\n",
    "    n_with_dineof = df['dineof_cvrms'].notna().sum()\n",
    "    n_with_dincae = df['dincae_cvrms'].notna().sum()\n",
    "    n_with_both = ((df['dineof_cvrms'].notna()) & (df['dincae_cvrms'].notna())).sum()\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"EXTRACTION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total lakes with data: {len(df)}\")\n",
    "    print(f\"  - With DINEOF CV-RMS: {n_with_dineof}\")\n",
    "    print(f\"  - With DINCAE CV-RMS: {n_with_dincae}\")\n",
    "    print(f\"  - With both: {n_with_both}\")\n",
    "    print(f\"Skipped (no data): {len(skipped_lakes)}\")\n",
    "    print()\n",
    "    print(\"Summary Statistics:\")\n",
    "    display(df.describe())\n",
    "    \n",
    "    print(\"\\nMissing values:\")\n",
    "    print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV: /gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/anomaly-20260131-219f0d-exp0_baseline_both/dineof_metrics.csv\n",
      "Saved JSON: /gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/anomaly-20260131-219f0d-exp0_baseline_both/dineof_metrics.json\n",
      "Saved skipped list: /gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/anomaly-20260131-219f0d-exp0_baseline_both/dineof_metrics_skipped.txt\n"
     ]
    }
   ],
   "source": [
    "# Ensure output directory exists\n",
    "out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save CSV\n",
    "csv_path = out_path / \"dineof_metrics.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Saved CSV: {csv_path}\")\n",
    "\n",
    "# Save JSON\n",
    "json_path = out_path / \"dineof_metrics.json\"\n",
    "n_with_dineof = int(df['dineof_cvrms'].notna().sum())\n",
    "n_with_dincae = int(df['dincae_cvrms'].notna().sum())\n",
    "n_with_both = int(((df['dineof_cvrms'].notna()) & (df['dincae_cvrms'].notna())).sum())\n",
    "\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'dineof_dir': str(dineof_base),\n",
    "        'dincae_dir': str(dincae_base),\n",
    "        'alpha_slug': ALPHA_SLUG,\n",
    "        'n_lakes': len(data_list),\n",
    "        'n_with_dineof_cvrms': n_with_dineof,\n",
    "        'n_with_dincae_cvrms': n_with_dincae,\n",
    "        'n_with_both': n_with_both,\n",
    "        'n_skipped': len(skipped_lakes),\n",
    "        'data': data_list\n",
    "    }, f, indent=2)\n",
    "print(f\"Saved JSON: {json_path}\")\n",
    "\n",
    "# Save skipped lakes\n",
    "skipped_path = out_path / \"dineof_metrics_skipped.txt\"\n",
    "with open(skipped_path, 'w') as f:\n",
    "    f.write(f\"# Lakes skipped (no metrics found)\\n\")\n",
    "    f.write(f\"# DINEOF dir: {dineof_base}\\n\")\n",
    "    f.write(f\"# DINCAE dir: {dincae_base}\\n\")\n",
    "    f.write(f\"# Total skipped: {len(skipped_lakes)}\\n\\n\")\n",
    "    for lake_id in skipped_lakes:\n",
    "        f.write(f\"{lake_id}\\n\")\n",
    "print(f\"Saved skipped list: {skipped_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: DINEOF vs DINCAE Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough data for visualization\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    if len(df) > 0 and df['dineof_cvrms'].notna().any() and df['dincae_cvrms'].notna().any():\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        # 1. DINEOF CV-RMS distribution\n",
    "        ax1 = axes[0, 0]\n",
    "        df['dineof_cvrms'].dropna().hist(ax=ax1, bins=30, edgecolor='black', alpha=0.7)\n",
    "        ax1.set_title('DINEOF CV-RMS Distribution')\n",
    "        ax1.set_xlabel('CV-RMS')\n",
    "        ax1.set_ylabel('Count')\n",
    "        \n",
    "        # 2. DINCAE CV-RMS distribution\n",
    "        ax2 = axes[0, 1]\n",
    "        df['dincae_cvrms'].dropna().hist(ax=ax2, bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "        ax2.set_title('DINCAE CV-RMS Distribution')\n",
    "        ax2.set_xlabel('CV-RMS')\n",
    "        ax2.set_ylabel('Count')\n",
    "        \n",
    "        # 3. DINEOF vs DINCAE scatter plot\n",
    "        ax3 = axes[1, 0]\n",
    "        both_mask = df['dineof_cvrms'].notna() & df['dincae_cvrms'].notna()\n",
    "        if both_mask.any():\n",
    "            df_both = df[both_mask]\n",
    "            ax3.scatter(df_both['dineof_cvrms'], df_both['dincae_cvrms'], alpha=0.6)\n",
    "            \n",
    "            # Add 1:1 line\n",
    "            lims = [\n",
    "                min(df_both['dineof_cvrms'].min(), df_both['dincae_cvrms'].min()),\n",
    "                max(df_both['dineof_cvrms'].max(), df_both['dincae_cvrms'].max())\n",
    "            ]\n",
    "            ax3.plot(lims, lims, 'r--', alpha=0.5, label='1:1 line')\n",
    "            ax3.set_xlabel('DINEOF CV-RMS')\n",
    "            ax3.set_ylabel('DINCAE CV-RMS')\n",
    "            ax3.set_title('DINEOF vs DINCAE CV-RMS')\n",
    "            ax3.legend()\n",
    "        else:\n",
    "            ax3.text(0.5, 0.5, 'No lakes with both\\nDINEOF and DINCAE data', \n",
    "                     ha='center', va='center', transform=ax3.transAxes)\n",
    "            ax3.set_title('DINEOF vs DINCAE CV-RMS')\n",
    "        \n",
    "        # 4. Variance ratio\n",
    "        ax4 = axes[1, 1]\n",
    "        if df['variance_initial'].notna().any() and df['variance_reconstructed'].notna().any():\n",
    "            var_ratio = df['variance_reconstructed'] / df['variance_initial']\n",
    "            var_ratio.dropna().hist(ax=ax4, bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "            ax4.axvline(1.0, color='red', linestyle='--', alpha=0.5, label='Ratio = 1.0')\n",
    "            ax4.set_title('Variance Ratio (Reconstructed / Initial)')\n",
    "            ax4.set_xlabel('Ratio')\n",
    "            ax4.set_ylabel('Count')\n",
    "            ax4.legend()\n",
    "        else:\n",
    "            ax4.text(0.5, 0.5, 'No variance data', ha='center', va='center', transform=ax4.transAxes)\n",
    "            ax4.set_title('Variance Ratio')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        fig_path = out_path / \"dineof_metrics_plots.png\"\n",
    "        plt.savefig(fig_path, dpi=150)\n",
    "        plt.show()\n",
    "        print(f\"Saved plots: {fig_path}\")\n",
    "    else:\n",
    "        print(\"Not enough data for visualization\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"matplotlib not available - skipping visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Map: CV-RMS by Lake Location\n",
    "\n",
    "This section creates global scatter plots showing CV-RMS values at each lake's geographic location.\n",
    "Dot size represents the error magnitude (larger dots = higher CV-RMS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded lake locations: 120 lakes\n",
      "Columns: ['lake_id', 'NAME', 'COUNTRY', 'MAX DISTANCE TO LAND (KM)', 'LAT CENTRE', 'LON CENTRE', 'N PIXELS LSWT_mean', 'N PIXELS LSWT_std', 'N PIXELS CLIM_mean', 'N PIXELS CLIM_std', 'LSWT_spatial_mean', 'LSWT_spatial_std', 'PIXELS_PERCENTAGE_mean', 'PIXELS_PERCENTAGE_std', 'max_N_no_obs_consecutive_days', 'N_no_obs_consecutive_days_mean', 'N_no_obs_consecutive_days_std', 'longest_duration_days', 'Freq_Rank', 'N_obs_days_mean', 'N_obs_days_std', 'selection', 'Insitu-only flag', 'LIC-only flag', 'LSWT-only flag', 'UOR_selection_flag', 'UOR_LIC_with_insitu_flag', 'lake_cluster_flag', 'Form ice flag']\n",
      "\n",
      "Renamed columns: lake_id, lat, lon\n",
      "Sample locations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lake_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>47.9625</td>\n",
       "      <td>-87.0431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>44.7208</td>\n",
       "      <td>-82.3458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>42.6042</td>\n",
       "      <td>-87.0153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>54.1736</td>\n",
       "      <td>108.9736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>66.0125</td>\n",
       "      <td>-120.3764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lake_id      lat       lon\n",
       "0        2  47.9625  -87.0431\n",
       "1        5  44.7208  -82.3458\n",
       "2        6  42.6042  -87.0153\n",
       "3        8  54.1736  108.9736\n",
       "4        9  66.0125 -120.3764"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load lake locations from CSV\n",
    "try:\n",
    "    df_locations = pd.read_csv(LAKE_LOCATIONS_CSV)\n",
    "    print(f\"Loaded lake locations: {len(df_locations)} lakes\")\n",
    "    print(f\"Columns: {list(df_locations.columns)}\")\n",
    "    \n",
    "    # Standardize column names (handle potential variations)\n",
    "    # Rename columns to lowercase for easier access\n",
    "    col_mapping = {}\n",
    "    for col in df_locations.columns:\n",
    "        if 'lake_id' in col.lower() or col.lower() == 'lake_id':\n",
    "            col_mapping[col] = 'lake_id'\n",
    "        elif 'lat' in col.lower() and 'centre' in col.lower():\n",
    "            col_mapping[col] = 'lat'\n",
    "        elif 'lon' in col.lower() and 'centre' in col.lower():\n",
    "            col_mapping[col] = 'lon'\n",
    "    \n",
    "    df_locations = df_locations.rename(columns=col_mapping)\n",
    "    print(f\"\\nRenamed columns: lake_id, lat, lon\")\n",
    "    print(f\"Sample locations:\")\n",
    "    display(df_locations[['lake_id', 'lat', 'lon']].head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Lake locations CSV not found: {LAKE_LOCATIONS_CSV}\")\n",
    "    print(\"Please ensure the CSV file is in the same directory as this notebook.\")\n",
    "    df_locations = None\n",
    "except Exception as e:\n",
    "    print(f\"ERROR loading lake locations: {e}\")\n",
    "    df_locations = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot merge - missing locations data or metrics data\n"
     ]
    }
   ],
   "source": [
    "# Merge metrics with locations\n",
    "if df_locations is not None and len(df) > 0:\n",
    "    # Merge on lake_id\n",
    "    df_merged = df.merge(df_locations[['lake_id', 'lat', 'lon']], on='lake_id', how='left')\n",
    "    \n",
    "    n_with_location = df_merged['lat'].notna().sum()\n",
    "    n_missing_location = df_merged['lat'].isna().sum()\n",
    "    \n",
    "    print(f\"Merged metrics with locations:\")\n",
    "    print(f\"  - Lakes with location: {n_with_location}\")\n",
    "    print(f\"  - Lakes missing location: {n_missing_location}\")\n",
    "    \n",
    "    if n_missing_location > 0:\n",
    "        missing_ids = df_merged[df_merged['lat'].isna()]['lake_id'].tolist()\n",
    "        print(f\"  - Missing lake IDs: {missing_ids[:10]}{'...' if len(missing_ids) > 10 else ''}\")\n",
    "    \n",
    "    display(df_merged.head())\n",
    "else:\n",
    "    df_merged = None\n",
    "    print(\"Cannot merge - missing locations data or metrics data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Cartopy for map projection\n",
      "No data with valid locations for global map\n"
     ]
    }
   ],
   "source": [
    "# Create global scatter plots\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # Try to import cartopy for proper map projection\n",
    "    try:\n",
    "        import cartopy.crs as ccrs\n",
    "        import cartopy.feature as cfeature\n",
    "        HAS_CARTOPY = True\n",
    "        print(\"Using Cartopy for map projection\")\n",
    "    except ImportError:\n",
    "        HAS_CARTOPY = False\n",
    "        print(\"Cartopy not available - using simple scatter plot\")\n",
    "    \n",
    "    if df_merged is not None and df_merged['lat'].notna().any():\n",
    "        # Filter to lakes with valid locations\n",
    "        df_plot = df_merged[df_merged['lat'].notna()].copy()\n",
    "        \n",
    "        # Scaling function for dot sizes\n",
    "        # Scale CV-RMS to reasonable dot sizes (min 20, max 200)\n",
    "        def scale_sizes(values, min_size=20, max_size=200):\n",
    "            valid = values.dropna()\n",
    "            if len(valid) == 0:\n",
    "                return values\n",
    "            vmin, vmax = valid.min(), valid.max()\n",
    "            if vmax == vmin:\n",
    "                return np.full_like(values, (min_size + max_size) / 2)\n",
    "            scaled = (values - vmin) / (vmax - vmin)\n",
    "            return min_size + scaled * (max_size - min_size)\n",
    "        \n",
    "        # Common colormap settings\n",
    "        cmap = 'YlOrRd'  # Yellow-Orange-Red colormap (low=yellow, high=red)\n",
    "        \n",
    "        if HAS_CARTOPY:\n",
    "            # ========== CARTOPY VERSION ==========\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(18, 8),\n",
    "                                     subplot_kw={'projection': ccrs.Robinson()})\n",
    "            \n",
    "            # --- DINEOF Plot ---\n",
    "            ax1 = axes[0]\n",
    "            ax1.set_global()\n",
    "            ax1.add_feature(cfeature.LAND, facecolor='lightgray', edgecolor='none')\n",
    "            ax1.add_feature(cfeature.OCEAN, facecolor='lightblue', alpha=0.3)\n",
    "            ax1.add_feature(cfeature.COASTLINE, linewidth=0.5, edgecolor='gray')\n",
    "            ax1.add_feature(cfeature.BORDERS, linewidth=0.3, edgecolor='gray', linestyle=':')\n",
    "            \n",
    "            df_dineof = df_plot[df_plot['dineof_cvrms'].notna()]\n",
    "            if len(df_dineof) > 0:\n",
    "                sizes = scale_sizes(df_dineof['dineof_cvrms'])\n",
    "                sc1 = ax1.scatter(df_dineof['lon'], df_dineof['lat'],\n",
    "                                  c=df_dineof['dineof_cvrms'], s=sizes,\n",
    "                                  cmap=cmap, alpha=0.7, edgecolors='black', linewidth=0.5,\n",
    "                                  transform=ccrs.PlateCarree())\n",
    "                cbar1 = plt.colorbar(sc1, ax=ax1, shrink=0.6, pad=0.02)\n",
    "                cbar1.set_label('CV-RMS', fontsize=10)\n",
    "            ax1.set_title(f'DINEOF CV-RMS (n={len(df_dineof)})', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # --- DINCAE Plot ---\n",
    "            ax2 = axes[1]\n",
    "            ax2.set_global()\n",
    "            ax2.add_feature(cfeature.LAND, facecolor='lightgray', edgecolor='none')\n",
    "            ax2.add_feature(cfeature.OCEAN, facecolor='lightblue', alpha=0.3)\n",
    "            ax2.add_feature(cfeature.COASTLINE, linewidth=0.5, edgecolor='gray')\n",
    "            ax2.add_feature(cfeature.BORDERS, linewidth=0.3, edgecolor='gray', linestyle=':')\n",
    "            \n",
    "            df_dincae = df_plot[df_plot['dincae_cvrms'].notna()]\n",
    "            if len(df_dincae) > 0:\n",
    "                sizes = scale_sizes(df_dincae['dincae_cvrms'])\n",
    "                sc2 = ax2.scatter(df_dincae['lon'], df_dincae['lat'],\n",
    "                                  c=df_dincae['dincae_cvrms'], s=sizes,\n",
    "                                  cmap=cmap, alpha=0.7, edgecolors='black', linewidth=0.5,\n",
    "                                  transform=ccrs.PlateCarree())\n",
    "                cbar2 = plt.colorbar(sc2, ax=ax2, shrink=0.6, pad=0.02)\n",
    "                cbar2.set_label('CV-RMS', fontsize=10)\n",
    "            ax2.set_title(f'DINCAE CV-RMS (n={len(df_dincae)})', fontsize=14, fontweight='bold')\n",
    "            \n",
    "        else:\n",
    "            # ========== SIMPLE VERSION (no Cartopy) ==========\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "            \n",
    "            # --- DINEOF Plot ---\n",
    "            ax1 = axes[0]\n",
    "            df_dineof = df_plot[df_plot['dineof_cvrms'].notna()]\n",
    "            if len(df_dineof) > 0:\n",
    "                sizes = scale_sizes(df_dineof['dineof_cvrms'])\n",
    "                sc1 = ax1.scatter(df_dineof['lon'], df_dineof['lat'],\n",
    "                                  c=df_dineof['dineof_cvrms'], s=sizes,\n",
    "                                  cmap=cmap, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "                cbar1 = plt.colorbar(sc1, ax=ax1, shrink=0.8)\n",
    "                cbar1.set_label('CV-RMS', fontsize=10)\n",
    "            ax1.set_xlabel('Longitude')\n",
    "            ax1.set_ylabel('Latitude')\n",
    "            ax1.set_xlim(-180, 180)\n",
    "            ax1.set_ylim(-90, 90)\n",
    "            ax1.set_title(f'DINEOF CV-RMS (n={len(df_dineof)})', fontsize=14, fontweight='bold')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # --- DINCAE Plot ---\n",
    "            ax2 = axes[1]\n",
    "            df_dincae = df_plot[df_plot['dincae_cvrms'].notna()]\n",
    "            if len(df_dincae) > 0:\n",
    "                sizes = scale_sizes(df_dincae['dincae_cvrms'])\n",
    "                sc2 = ax2.scatter(df_dincae['lon'], df_dincae['lat'],\n",
    "                                  c=df_dincae['dincae_cvrms'], s=sizes,\n",
    "                                  cmap=cmap, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "                cbar2 = plt.colorbar(sc2, ax=ax2, shrink=0.8)\n",
    "                cbar2.set_label('CV-RMS', fontsize=10)\n",
    "            ax2.set_xlabel('Longitude')\n",
    "            ax2.set_ylabel('Latitude')\n",
    "            ax2.set_xlim(-180, 180)\n",
    "            ax2.set_ylim(-90, 90)\n",
    "            ax2.set_title(f'DINCAE CV-RMS (n={len(df_dincae)})', fontsize=14, fontweight='bold')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle('Global Distribution of CV-RMS Errors\\n(dot size = error magnitude)', \n",
    "                     fontsize=16, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        fig_path = out_path / \"dineof_metrics_global_map.png\"\n",
    "        plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"\\nSaved global map: {fig_path}\")\n",
    "    else:\n",
    "        print(\"No data with valid locations for global map\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"matplotlib not available - skipping global map: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side-by-side comparison map with same color scale\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    if df_merged is not None and df_merged['lat'].notna().any():\n",
    "        # Get lakes with BOTH methods for fair comparison\n",
    "        df_both_loc = df_merged[\n",
    "            (df_merged['lat'].notna()) & \n",
    "            (df_merged['dineof_cvrms'].notna()) & \n",
    "            (df_merged['dincae_cvrms'].notna())\n",
    "        ].copy()\n",
    "        \n",
    "        if len(df_both_loc) > 0:\n",
    "            print(f\"Lakes with both DINEOF and DINCAE + location: {len(df_both_loc)}\")\n",
    "            \n",
    "            # Use same color scale for both plots\n",
    "            vmin = min(df_both_loc['dineof_cvrms'].min(), df_both_loc['dincae_cvrms'].min())\n",
    "            vmax = max(df_both_loc['dineof_cvrms'].max(), df_both_loc['dincae_cvrms'].max())\n",
    "            \n",
    "            # Calculate which method is better for each lake\n",
    "            df_both_loc['better_method'] = np.where(\n",
    "                df_both_loc['dineof_cvrms'] < df_both_loc['dincae_cvrms'],\n",
    "                'DINEOF', 'DINCAE'\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                import cartopy.crs as ccrs\n",
    "                import cartopy.feature as cfeature\n",
    "                HAS_CARTOPY = True\n",
    "            except ImportError:\n",
    "                HAS_CARTOPY = False\n",
    "            \n",
    "            # Create figure with 3 subplots: DINEOF, DINCAE, and Winner\n",
    "            if HAS_CARTOPY:\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(20, 6),\n",
    "                                         subplot_kw={'projection': ccrs.Robinson()})\n",
    "                \n",
    "                for ax in axes:\n",
    "                    ax.set_global()\n",
    "                    ax.add_feature(cfeature.LAND, facecolor='lightgray', edgecolor='none')\n",
    "                    ax.add_feature(cfeature.OCEAN, facecolor='lightblue', alpha=0.3)\n",
    "                    ax.add_feature(cfeature.COASTLINE, linewidth=0.5, edgecolor='gray')\n",
    "                \n",
    "                # DINEOF\n",
    "                sizes1 = scale_sizes(df_dineof['dineof_cvrms'])                \n",
    "                sc1 = axes[0].scatter(df_both_loc['lon'], df_both_loc['lat'],\n",
    "                                      c=df_both_loc['dineof_cvrms'], s=80,\n",
    "                                      cmap='YlOrRd', vmin=vmin, vmax=vmax,\n",
    "                                      alpha=0.8, edgecolors='black', linewidth=0.5,\n",
    "                                      transform=ccrs.PlateCarree())\n",
    "                axes[0].set_title('DINEOF CV-RMS', fontsize=12, fontweight='bold')\n",
    "                \n",
    "                # DINCAE\n",
    "                sizes2 = scale_sizes(df_dineof['dincae_cvrms'])                               \n",
    "                sc2 = axes[1].scatter(df_both_loc['lon'], df_both_loc['lat'],\n",
    "                                      c=df_both_loc['dincae_cvrms'], s=80,\n",
    "                                      cmap='YlOrRd', vmin=vmin, vmax=vmax,\n",
    "                                      alpha=0.8, edgecolors='black', linewidth=0.5,\n",
    "                                      transform=ccrs.PlateCarree())\n",
    "                axes[1].set_title('DINCAE CV-RMS', fontsize=12, fontweight='bold')\n",
    "                \n",
    "                # Winner map\n",
    "                colors = df_both_loc['better_method'].map({'DINEOF': 'blue', 'DINCAE': 'orange'})\n",
    "                axes[2].scatter(df_both_loc['lon'], df_both_loc['lat'],\n",
    "                                c=colors, s=80, alpha=0.8, edgecolors='black', linewidth=0.5,\n",
    "                                transform=ccrs.PlateCarree())\n",
    "                # Add legend\n",
    "                from matplotlib.patches import Patch\n",
    "                n_dineof_wins = (df_both_loc['better_method'] == 'DINEOF').sum()\n",
    "                n_dincae_wins = (df_both_loc['better_method'] == 'DINCAE').sum()\n",
    "                legend_elements = [\n",
    "                    Patch(facecolor='blue', edgecolor='black', label=f'DINEOF better ({n_dineof_wins})'),\n",
    "                    Patch(facecolor='orange', edgecolor='black', label=f'DINCAE better ({n_dincae_wins})')\n",
    "                ]\n",
    "                axes[2].legend(handles=legend_elements, loc='lower left', fontsize=9)\n",
    "                axes[2].set_title('Better Method (lower CV-RMS)', fontsize=12, fontweight='bold')\n",
    "                \n",
    "            else:\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "                \n",
    "                # DINEOF\n",
    "                sc1 = axes[0].scatter(df_both_loc['lon'], df_both_loc['lat'],\n",
    "                                      c=df_both_loc['dineof_cvrms'], s=80,\n",
    "                                      cmap='YlOrRd', vmin=vmin, vmax=vmax,\n",
    "                                      alpha=0.8, edgecolors='black', linewidth=0.5)\n",
    "                axes[0].set_title('DINEOF CV-RMS', fontsize=12, fontweight='bold')\n",
    "                axes[0].set_xlim(-180, 180)\n",
    "                axes[0].set_ylim(-90, 90)\n",
    "                axes[0].grid(True, alpha=0.3)\n",
    "                \n",
    "                # DINCAE\n",
    "                sc2 = axes[1].scatter(df_both_loc['lon'], df_both_loc['lat'],\n",
    "                                      c=df_both_loc['dincae_cvrms'], s=80,\n",
    "                                      cmap='YlOrRd', vmin=vmin, vmax=vmax,\n",
    "                                      alpha=0.8, edgecolors='black', linewidth=0.5)\n",
    "                axes[1].set_title('DINCAE CV-RMS', fontsize=12, fontweight='bold')\n",
    "                axes[1].set_xlim(-180, 180)\n",
    "                axes[1].set_ylim(-90, 90)\n",
    "                axes[1].grid(True, alpha=0.3)\n",
    "                \n",
    "                # Winner map\n",
    "                colors = df_both_loc['better_method'].map({'DINEOF': 'blue', 'DINCAE': 'orange'})\n",
    "                axes[2].scatter(df_both_loc['lon'], df_both_loc['lat'],\n",
    "                                c=colors, s=80, alpha=0.8, edgecolors='black', linewidth=0.5)\n",
    "                n_dineof_wins = (df_both_loc['better_method'] == 'DINEOF').sum()\n",
    "                n_dincae_wins = (df_both_loc['better_method'] == 'DINCAE').sum()\n",
    "                from matplotlib.patches import Patch\n",
    "                legend_elements = [\n",
    "                    Patch(facecolor='blue', edgecolor='black', label=f'DINEOF better ({n_dineof_wins})'),\n",
    "                    Patch(facecolor='orange', edgecolor='black', label=f'DINCAE better ({n_dincae_wins})')\n",
    "                ]\n",
    "                axes[2].legend(handles=legend_elements, loc='lower left', fontsize=9)\n",
    "                axes[2].set_title('Better Method (lower CV-RMS)', fontsize=12, fontweight='bold')\n",
    "                axes[2].set_xlim(-180, 180)\n",
    "                axes[2].set_ylim(-90, 90)\n",
    "                axes[2].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add shared colorbar\n",
    "            fig.subplots_adjust(bottom=0.15)\n",
    "            cbar_ax = fig.add_axes([0.15, 0.08, 0.5, 0.03])\n",
    "            cbar = fig.colorbar(sc1, cax=cbar_ax, orientation='horizontal')\n",
    "            cbar.set_label('CV-RMS (same scale for DINEOF and DINCAE)', fontsize=11)\n",
    "            \n",
    "            plt.suptitle(f'CV-RMS Comparison: DINEOF vs DINCAE (n={len(df_both_loc)} lakes with both methods)',\n",
    "                         fontsize=14, fontweight='bold', y=0.98)\n",
    "            \n",
    "            # Save figure\n",
    "            fig_path = out_path / \"dineof_metrics_global_comparison.png\"\n",
    "            plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            print(f\"\\nSaved comparison map: {fig_path}\")\n",
    "        else:\n",
    "            print(\"No lakes with both DINEOF and DINCAE data + location for comparison map\")\n",
    "            \n",
    "except ImportError as e:\n",
    "    print(f\"Error creating comparison map: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Analysis: Which Method Performs Better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df) > 0:\n",
    "    both_mask = df['dineof_cvrms'].notna() & df['dincae_cvrms'].notna()\n",
    "    df_both = df[both_mask].copy()\n",
    "    \n",
    "    if len(df_both) > 0:\n",
    "        df_both['cvrms_diff'] = df_both['dincae_cvrms'] - df_both['dineof_cvrms']\n",
    "        df_both['dineof_better'] = df_both['dineof_cvrms'] < df_both['dincae_cvrms']\n",
    "        df_both['dincae_better'] = df_both['dincae_cvrms'] < df_both['dineof_cvrms']\n",
    "        \n",
    "        n_dineof_better = df_both['dineof_better'].sum()\n",
    "        n_dincae_better = df_both['dincae_better'].sum()\n",
    "        n_equal = len(df_both) - n_dineof_better - n_dincae_better\n",
    "        \n",
    "        print(f\"Lakes with both DINEOF and DINCAE: {len(df_both)}\")\n",
    "        print(f\"  - DINEOF better (lower CV-RMS): {n_dineof_better} ({100*n_dineof_better/len(df_both):.1f}%)\")\n",
    "        print(f\"  - DINCAE better (lower CV-RMS): {n_dincae_better} ({100*n_dincae_better/len(df_both):.1f}%)\")\n",
    "        print(f\"  - Equal: {n_equal}\")\n",
    "        print()\n",
    "        print(f\"Mean DINEOF CV-RMS: {df_both['dineof_cvrms'].mean():.4f}\")\n",
    "        print(f\"Mean DINCAE CV-RMS: {df_both['dincae_cvrms'].mean():.4f}\")\n",
    "        print(f\"Mean difference (DINCAE - DINEOF): {df_both['cvrms_diff'].mean():.4f}\")\n",
    "        \n",
    "        # Show all lakes where DINCAE is better (any amount)\n",
    "        print(\"\\nLakes where DINCAE is better (lower CV-RMS):\")\n",
    "        dincae_better_lakes = df_both[df_both['dincae_better']][['lake_id', 'dineof_cvrms', 'dincae_cvrms', 'cvrms_diff']].sort_values('cvrms_diff')\n",
    "        if len(dincae_better_lakes) > 0:\n",
    "            print(f\"  Lake IDs: {dincae_better_lakes['lake_id'].tolist()}\")\n",
    "            display(dincae_better_lakes)\n",
    "        else:\n",
    "            print(\"  None\")\n",
    "        \n",
    "        print(\"\\nLakes where DINCAE significantly outperforms DINEOF (diff < -0.1):\")\n",
    "        dincae_wins = df_both[df_both['cvrms_diff'] < -0.1][['lake_id', 'dineof_cvrms', 'dincae_cvrms', 'cvrms_diff']]\n",
    "        if len(dincae_wins) > 0:\n",
    "            display(dincae_wins.head(10))\n",
    "        else:\n",
    "            print(\"  None\")\n",
    "    else:\n",
    "        print(\"No lakes with both DINEOF and DINCAE data for comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DONE!\n",
      "============================================================\n",
      "\n",
      "Output files saved to: /gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/gws/ssde/j25b/cds_c3s_lakes/users/SHAERDAN/anomaly-20260131-219f0d-exp0_baseline_both\n",
      "  - dineof_metrics.csv\n",
      "  - dineof_metrics.json\n",
      "  - dineof_metrics_skipped.txt\n",
      "  - dineof_metrics_plots.png\n",
      "  - dineof_metrics_global_map.png\n",
      "  - dineof_metrics_global_comparison.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DONE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOutput files saved to: {out_path}\")\n",
    "print(f\"  - dineof_metrics.csv\")\n",
    "print(f\"  - dineof_metrics.json\")\n",
    "print(f\"  - dineof_metrics_skipped.txt\")\n",
    "print(f\"  - dineof_metrics_plots.png\")\n",
    "print(f\"  - dineof_metrics_global_map.png\")\n",
    "print(f\"  - dineof_metrics_global_comparison.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (latest Jaspy)",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
