{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db7d75ec-d5ac-459c-8a9c-9889f23b1dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected pixel at indices: lat_index = 20, lon_index = 35\n",
      "[0.94000244 0.5799866         nan ...        nan        nan 1.1700134 ]\n",
      "[276.44    275.91998       nan ...       nan       nan 277.57   ]\n",
      "[274.81    274.69998 274.62    ... 275.82    275.77    275.69   ]\n",
      "Original plot saved as original_plot.png\n",
      "Climatology plot saved as climatology_plot.png\n",
      "Processed plot saved as processed_plot.png\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# Use an interactive backend if you like, or non-interactive if running on a remote server:\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "# ---------------------------\n",
    "# Define file paths (modify as needed)\n",
    "# ---------------------------\n",
    "original_path = \"/gws/smf/j04/cds_c3s_lakes/LAURA/TIME_SERIES_PL_L3C/PER_LAKE_TIME_SERIES/LAKE_TS/v2.6.1-146-gfe50b81_RES20_v124_rep/LAKE000000012-ESACCI-v2.0.2_v2.1_EOCIS-L3S-LSWT-CDR-4.5-fv01.0.nc\"\n",
    "climatology_path = \"/gws/smf/j04/cds_c3s_lakes/LAURA/TIME_SERIES_PL_L3C/PER_LAKE_CLIM_OBS/LAKE_CLIM_OBS/v2.6.1-146-gfe50b81_RES20_1995_2020/LAKE000000012_CLIM.nc\"\n",
    "processed_path = \"/gws/nopw/j04/eocis_chuk/shaerdan/lake/lake_data/dineof_test_12_coarse/prepared.nc\"\n",
    "\n",
    "# ---------------------------\n",
    "# Load the datasets\n",
    "# ---------------------------\n",
    "ds_orig = xr.open_dataset(original_path)\n",
    "ds_proc = xr.open_dataset(processed_path)\n",
    "ds_clim = xr.open_dataset(climatology_path)\n",
    "\n",
    "# ---------------------------\n",
    "# Automatically select a pixel with at least 300 non-empty (non-zero) entries in ds_proc.\n",
    "# ---------------------------\n",
    "non_empty_counts = (ds_proc[\"lake_surface_water_temperature\"] != 0).sum(dim=\"time\")\n",
    "counts_np = non_empty_counts.values  # shape: (nlat, nlon)\n",
    "i, j = np.where(counts_np >= 300)\n",
    "if len(i) == 0:\n",
    "    raise ValueError(\"No pixel found with at least 300 non-empty entries.\")\n",
    "lat_index = 20\n",
    "lon_index = 35\n",
    "print(\"Selected pixel at indices: lat_index = {}, lon_index = {}\".format(lat_index, lon_index))\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Extract time series from the processed (subtracted) dataset\n",
    "# ---------------------------\n",
    "ts_proc = ds_proc[\"lake_surface_water_temperature\"].isel(lat=lat_index, lon=lon_index)\n",
    "print(ts_proc.values)\n",
    "# ---------------------------\n",
    "# Build a time axis for the processed dataset\n",
    "# ---------------------------\n",
    "# In the preprocessor, time was converted to days since 1981-01-01 12:00:00.\n",
    "ref_date = datetime.datetime(1981, 1, 1, 12, 0, 0)\n",
    "# Create a list of datetime objects from the processed time values\n",
    "time_proc = [ref_date + datetime.timedelta(days=int(t)) for t in ds_proc[\"time\"].values]\n",
    "# Convert the list to a NumPy array of dtype datetime64[ns]\n",
    "time_proc_dt = np.array(time_proc, dtype=\"datetime64[ns]\")\n",
    "\n",
    "# ---------------------------\n",
    "# Extract time series from the original dataset.\n",
    "# Use the converted processed time coordinate for selection.\n",
    "# ---------------------------\n",
    "ts_orig = ds_orig[\"lake_surface_water_temperature\"].sel(time=time_proc_dt, method=\"nearest\") \\\n",
    "            .isel(lat=lat_index, lon=lon_index)\n",
    "print(ts_orig.values)\n",
    "# ---------------------------\n",
    "# For the climatology, we need to get the value for each processed time.\n",
    "# The climatology file has 366 entries (one per day-of-year).  \n",
    "# Here we compute the day-of-year for each processed time and then select the nearest climatology slice.\n",
    "# ---------------------------\n",
    "# Ensure the climatology variable has a coordinate \"doy\"\n",
    "clim_da = ds_clim[\"lswt_mean_trimmed_345\"]\n",
    "if \"doy\" not in clim_da.coords:\n",
    "    clim_da = clim_da.rename({\"time\": \"doy\"})\n",
    "    clim_da = clim_da.assign_coords(doy=np.arange(1, clim_da.sizes[\"doy\"] + 1))\n",
    "\n",
    "# Compute day-of-year for each processed time (using the datetime objects)\n",
    "doys = [t.timetuple().tm_yday for t in time_proc]\n",
    "\n",
    "# For each time in the processed dataset, select the climatology slice using the day-of-year.\n",
    "# Use nearest-neighbor selection.\n",
    "ts_clim_values = []\n",
    "for doy in doys:\n",
    "    clim_val = clim_da.sel(doy=doy, method=\"nearest\").isel(lat=lat_index, lon=lon_index).values\n",
    "    ts_clim_values.append(clim_val)\n",
    "# Wrap the climatology values in a DataArray, using the same time coordinate as the processed dataset\n",
    "ts_clim = xr.DataArray(ts_clim_values, dims=[\"time\"], coords={\"time\": time_proc_dt})\n",
    "print(ts_clim.values)\n",
    "\n",
    "# print(ts_orig.values)\n",
    "# print(ts_clim.values)\n",
    "# print(ts_proc.values)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Filter out NaN values and prepare a common time array\n",
    "# ----------------------------------------------------\n",
    "# Convert the processed time list (time_proc) to a NumPy array for filtering.\n",
    "time_array = np.array(time_proc)\n",
    "\n",
    "# Create masks for non-NaN values for each time series.\n",
    "mask_orig = ~np.isnan(ts_orig.values)\n",
    "mask_clim = ~np.isnan(ts_clim.values)\n",
    "mask_proc = ~np.isnan(ts_proc.values)\n",
    "\n",
    "# Filter the time coordinate based on each mask.\n",
    "time_orig_filtered = time_array[mask_orig]\n",
    "time_clim_filtered = time_array[mask_clim]\n",
    "time_proc_filtered = time_array[mask_proc]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Plot 1: Original Data (in Kelvin)\n",
    "# ----------------------------------------------------\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_orig_filtered, ts_orig.values[mask_orig], 'o-', label=\"Original\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Temperature (K)\")\n",
    "plt.title(\"Original Data at Pixel (lat index {}, lon index {})\".format(lat_index, lon_index))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"original_plot.png\")\n",
    "plt.show()\n",
    "print(\"Original plot saved as original_plot.png\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Plot 2: Climatology Data (in Kelvin)\n",
    "# ----------------------------------------------------\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_clim_filtered, ts_clim.values[mask_clim], 'o-', label=\"Climatology\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Temperature (K)\")\n",
    "plt.title(\"Climatology Data at Pixel (lat index {}, lon index {})\".format(lat_index, lon_index))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"climatology_plot.png\")\n",
    "plt.show()\n",
    "print(\"Climatology plot saved as climatology_plot.png\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Plot 3: Processed Data (Original minus Climatology)\n",
    "# (This will show differences typically below 10 K.)\n",
    "# ----------------------------------------------------\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_proc_filtered, ts_proc.values[mask_proc], 'o-', label=\"Processed (Original - Climatology)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Difference (K)\")\n",
    "plt.title(\"Processed Data at Pixel (lat index {}, lon index {})\".format(lat_index, lon_index))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"processed_plot.png\")\n",
    "plt.show()\n",
    "print(\"Processed plot saved as processed_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28f2fe3d-60f0-43c7-b5dc-8039bb2d7dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Processed values do not match the expected values.\n",
      "Max absolute difference: 0.85998535\n",
      "Time index 0: Original = 276.44000244140625, Climatology = 274.80999755859375, Expected Processed = 1.6300048828125, Processed = 0.94000244140625\n",
      "Time index 1: Original = 275.91998291015625, Climatology = 274.6999816894531, Expected Processed = 1.220001220703125, Processed = 0.579986572265625\n",
      "Time index 2: Original = nan, Climatology = 274.6199951171875, Expected Processed = nan, Processed = nan\n",
      "Time index 3: Original = nan, Climatology = 274.3500061035156, Expected Processed = nan, Processed = nan\n",
      "Time index 4: Original = nan, Climatology = 274.0199890136719, Expected Processed = nan, Processed = nan\n"
     ]
    }
   ],
   "source": [
    "expected = np.where(\n",
    "    (ts_orig.values == 0) | np.isnan(ts_clim.values),\n",
    "    0,\n",
    "    ts_orig.values - ts_clim.values\n",
    ")\n",
    "\n",
    "# Calculate the difference between the expected and the actual processed values.\n",
    "diff = ts_proc.values - expected\n",
    "\n",
    "# Use a tolerance for floating point differences.\n",
    "tolerance = 1e-6\n",
    "if not np.allclose(ts_proc.values, expected, atol=tolerance, equal_nan=True):\n",
    "    print(\"Warning: Processed values do not match the expected values.\")\n",
    "    print(\"Max absolute difference:\", np.nanmax(np.abs(diff)))\n",
    "else:\n",
    "    print(\"Processed values match the expected values.\")\n",
    "\n",
    "# Optionally, print out some sample comparisons for a few time steps:\n",
    "for idx in range(min(5, len(ts_proc))):\n",
    "    print(f\"Time index {idx}: Original = {ts_orig.values[idx]}, Climatology = {ts_clim.values[idx]}, \"\n",
    "          f\"Expected Processed = {expected[idx]}, Processed = {ts_proc.values[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03d0ace5-472d-4110-96fd-f723ebc0cf0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/gws/nopw/j04/eocis_chuk/shaerdan/lake/lake_data/dineof_test_12_coarse/prepared.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/gws/nopw/j04/eocis_chuk/shaerdan/lake/lake_data/dineof_test_12_coarse/prepared.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), 'd9fe4c04-83cb-4436-9f91-852d85104ba7']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m ds_orig   \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(original_path)\n\u001b[1;32m     19\u001b[0m ds_clim   \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(climatology_path)\n\u001b[0;32m---> 20\u001b[0m ds_proc   \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Select a sample pixel (change indices as desired)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[1;32m     25\u001b[0m lat_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/api.py:588\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    577\u001b[0m     decode_cf,\n\u001b[1;32m    578\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    584\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    585\u001b[0m )\n\u001b[1;32m    587\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 588\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    595\u001b[0m     backend_ds,\n\u001b[1;32m    596\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    607\u001b[0m )\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:645\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]  # allow LSP violation, not supporting **kwargs\u001b[39;00m\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    626\u001b[0m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike[Any] \u001b[38;5;241m|\u001b[39m BufferedIOBase \u001b[38;5;241m|\u001b[39m AbstractDataStore,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    642\u001b[0m     autoclose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    643\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[1;32m    644\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 645\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mNetCDF4DataStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:408\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    402\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    403\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[1;32m    404\u001b[0m )\n\u001b[1;32m    405\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    406\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    407\u001b[0m )\n\u001b[0;32m--> 408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:355\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:417\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:411\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 411\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_nc4_require_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2470\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2107\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/gws/nopw/j04/eocis_chuk/shaerdan/lake/lake_data/dineof_test_12_coarse/prepared.nc'"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# Use an interactive backend if you like, or non-interactive if running on a remote server:\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "# ---------------------------\n",
    "# Define file paths (modify as needed)\n",
    "# ---------------------------\n",
    "original_path = \"/gws/smf/j04/cds_c3s_lakes/LAURA/TIME_SERIES_PL_L3C/PER_LAKE_TIME_SERIES/LAKE_TS/v2.6.1-146-gfe50b81_RES20_v124_rep/LAKE000000012-ESACCI-v2.0.2_v2.1_EOCIS-L3S-LSWT-CDR-4.5-fv01.0.nc\"\n",
    "climatology_path = \"/gws/smf/j04/cds_c3s_lakes/LAURA/TIME_SERIES_PL_L3C/PER_LAKE_CLIM_OBS/LAKE_CLIM_OBS/v2.6.1-146-gfe50b81_RES20_1995_2020/LAKE000000012_CLIM.nc\"\n",
    "processed_path = \"/gws/nopw/j04/eocis_chuk/shaerdan/lake/lake_data/dineof_test_12_coarse/prepared.nc\"\n",
    "\n",
    "# ---------------------------\n",
    "# Load the datasets\n",
    "# ---------------------------\n",
    "ds_orig   = xr.open_dataset(original_path)\n",
    "ds_clim   = xr.open_dataset(climatology_path)\n",
    "ds_proc   = xr.open_dataset(processed_path)\n",
    "\n",
    "# ---------------------------\n",
    "# Select a sample pixel (change indices as desired)\n",
    "# ---------------------------\n",
    "lat_index = 20\n",
    "lon_index = 35\n",
    "\n",
    "# ---------------------------\n",
    "# Build the time axis from the processed dataset\n",
    "# ---------------------------\n",
    "# In the preprocessor, time was converted to days since 1981-01-01 12:00:00.\n",
    "ref_date = datetime.datetime(1981, 1, 1, 12, 0, 0)\n",
    "time_proc = [ref_date + datetime.timedelta(days=int(t)) for t in ds_proc[\"time\"].values]\n",
    "# Convert to NumPy datetime64 array\n",
    "time_proc_dt = np.array(time_proc, dtype=\"datetime64[ns]\")\n",
    "\n",
    "# ---------------------------\n",
    "# Extract the original time series at the sample pixel\n",
    "# ---------------------------\n",
    "# Since the times match exactly, we can select using the processed time axis.\n",
    "ts_orig = ds_orig[\"lake_surface_water_temperature\"].sel(time=time_proc_dt).isel(lat=lat_index, lon=lon_index)\n",
    "\n",
    "# ---------------------------\n",
    "# Prepare the climatology\n",
    "# ---------------------------\n",
    "clim_da = ds_clim[\"lswt_mean_trimmed_345\"]\n",
    "# Ensure a day-of-year coordinate exists.\n",
    "if \"doy\" not in clim_da.coords:\n",
    "    clim_da = clim_da.rename({\"time\": \"doy\"})\n",
    "    clim_da = clim_da.assign_coords(doy=np.arange(1, clim_da.sizes[\"doy\"] + 1))\n",
    "\n",
    "# Compute day-of-year for each time in time_proc.\n",
    "doys = [t.timetuple().tm_yday for t in time_proc]\n",
    "\n",
    "# For each time step, select the corresponding climatology value at the sample pixel.\n",
    "ts_clim_values = []\n",
    "for doy in doys:\n",
    "    clim_val = clim_da.sel(doy=doy).isel(lat=lat_index, lon=lon_index).values\n",
    "    ts_clim_values.append(clim_val)\n",
    "ts_clim = xr.DataArray(ts_clim_values, dims=[\"time\"], coords={\"time\": time_proc_dt})\n",
    "\n",
    "# ---------------------------\n",
    "# Compute the expected processed values:\n",
    "# If original == 0 or climatology is NaN, expected = 0; else expected = original - climatology.\n",
    "# ---------------------------\n",
    "expected = np.where((ts_orig.values == 0) | np.isnan(ts_clim.values),\n",
    "                    0,\n",
    "                    ts_orig.values - ts_clim.values)\n",
    "\n",
    "# ---------------------------\n",
    "# Extract the processed time series at the sample pixel\n",
    "# ---------------------------\n",
    "ts_proc = ds_proc[\"lake_surface_water_temperature\"].isel(lat=lat_index, lon=lon_index)\n",
    "processed_values = ts_proc.values\n",
    "\n",
    "# ---------------------------\n",
    "# Compare expected and processed values\n",
    "# ---------------------------\n",
    "diff = processed_values - expected\n",
    "tolerance = 1e-6\n",
    "if np.allclose(processed_values, expected, atol=tolerance, equal_nan=True):\n",
    "    print(\"Processed values match the expected values.\")\n",
    "else:\n",
    "    print(\"Mismatch found: maximum absolute difference is\", np.nanmax(np.abs(diff)))\n",
    "    # Print a few sample comparisons\n",
    "    for idx in range(min(5, len(ts_proc))):\n",
    "        print(f\"Time index {idx}: Original = {ts_orig.values[idx]}, \"\n",
    "              f\"Climatology = {ts_clim.values[idx]}, \"\n",
    "              f\"Expected = {expected[idx]}, \"\n",
    "              f\"Processed = {processed_values[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61684dc5-b638-4247-b46b-f09a2a2e9646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
